#!/bin/bash -l
#PBS -l nodes=2:ppn=24
#PBS -l walltime=1:00:00
#PBS -l pmem=8gb
#PBS -N June29_netviz_1930
#PBS -m b -M mhscientist@gmail.com
 


# load appropriate MPI implementation module
module unload intel
module purge
module use 
module load intel/2018a

# set worker application and options
WORKER_APPL="/vsc-hard-mounts/leuven-apps/skylake/2018a/software/worker/1.6.10-intel-2018a/lib/../bin/worker"

# get the job ID and to compute appropriate names
WORKER_JOBID=`echo $PBS_JOBID | sed 's/\([0-9][0-9]*\).*/\1/'`

# change to the working directory
cd $PBS_O_WORKDIR

# rename artifacts consistently with job name and ID scheme
mv .workerQn_F/job20190629_netviz.sh.worker ${PBS_JOBNAME}.sh${WORKER_JOBID}
mv .workerQn_F/job20190629_netviz.sh.run ${PBS_JOBNAME}.run${WORKER_JOBID}
mv .workerQn_F/worker.pbs ${PBS_JOBNAME}.pbs${WORKER_JOBID}

# compute prolog option

WORKER_PROLOG=""

# master sleep time to avoid MPI_Test spinning load
WORKER_SLEEP="-s 10000"

# compute batch option
WORKER_BATCH="-b ${PBS_JOBNAME}.sh${WORKER_JOBID}"

# compute epilog option

WORKER_EPILOG=""

rm -rf .workerQn_F/

# determine the number of processes to run, modify later if master
# or threaded switch is active
n_proc=$(cat ${PBS_NODEFILE} | wc -l)

# only applicable when the master switch is on
# create host file to use for this job and compute number of cores


# only applicable when the threaded swith is on


# compute log option
WORKER_LOG_FILE="-l ${PBS_JOBNAME}.log${WORKER_JOBID}"

# compute verbose option
WORKER_VERBOSE=""

# start the worker
mpirun  ${mpi_opt} ${ppn_opt} \
    "${WORKER_APPL}" ${WORKER_PROLOG} ${WORKER_BATCH} ${WORKER_EPILOG} \
                   ${WORKER_LOG_FILE} ${WORKER_VERBOSE} ${WORKER_SLEEP} \
                   ${WORKER_THREADS}
